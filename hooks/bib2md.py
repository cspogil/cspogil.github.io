"""Parse all BibTeX entries and generate the corresponding Markdown content.

The `on_files` hook parses all activities and research files, populates the
global `ACTS` and `PUBS` variables, and adds new files to the build output:

  - For each activity page, a `.bib` file is generated (see `write_entry`).
  - For each research page, a `.md` file is generated (see `write_page`).

The `on_page_markdown` hook generates a table of contents at the bottom of
`activities/index.md` and `research/index.md` (see `write_index`).
"""

import io
import logging
import re

import bibtexparser
from mkdocs.structure.files import File

LOG = logging.getLogger('mkdocs')

# Warning at the top of each generated Markdown file
WARN = "<!-- DO NOT EDIT THIS FILE (automatically generated by bib2md.py) -->"

# All activities and publications (map src_uri to bibtex Entry)
ACTS = {}
PUBS = {}


def parse_entry(code_or_path):
    """Parse the given code block or bib file and return the entry."""

    # Is the string a code block or file path?
    if code_or_path.startswith("@"):
        library = bibtexparser.parse_string(code_or_path)
    else:
        library = bibtexparser.parse_file(code_or_path)

    # Abort if the BiBTeX format is incorrect
    n = len(library.failed_blocks)
    if n > 0:
        LOG.warning(f"{n} blocks failed to parse")
    n = len(library.entries)
    if n != 1:
        LOG.warning(f"{n} entries found (not 1)")
    return library.entries[0]


def reformat_authors(author_string):
    """Convert author string to "First Last" format, separated by commas."""
    authors = author_string.split(" and ")
    reformatted = []
    for author in authors:
        if "," in author:
            last, first = [part.strip() for part in author.split(",", 1)]
            reformatted.append(f"{first} {last}")
        else:
            # Already in "First Last" format
            reformatted.append(author.strip())
    return ", ".join(reformatted)


def abbreviate(url):
    """Shorten the URL for better text wrapping."""
    pos = url.index("/", 8)
    return url[:pos+1] + "..."


def get_fields(entry):
    """Extract common fields used in references and summary tables."""
    fields = entry.fields_dict
    author = fields["author"].value
    author = reformat_authors(author)
    year = fields["year"].value
    title = fields["title"].value

    # Get the source in order of priority
    source = None
    for fkey in ["series", "booktitle", "journal", "publisher", "howpublished"]:
        if fkey in fields:
            source = fields[fkey].value
            break

    # Default to short url if not found
    if not source:
        url = fields["url"].value
        abbr = abbreviate(url)
        source = f"[{abbr}]({url})"

    return author, year, title, source


def write_entry(entry, out):
    """Output the entry (activity or publication) in Markdown format."""

    # Write the "Abstract" section if present
    field = entry.fields_dict.get("abstract")
    if field:
        out.write("\n## Abstract\n\n")
        out.write(field.value + "\n")

    # Write the "Contents" section if present
    field = entry.fields_dict.get("contents")
    if field:

        # Get the index after the left brace
        pattern = r"^\s*contents\s*=\s*{"
        match = re.search(pattern, entry.raw, re.MULTILINE)
        col = len(match.group())

        # Remove leading whitespace from each line
        lines = field.value.splitlines()
        for i in range(1, len(lines)):
            line = lines[i]
            beg = 0
            while beg < len(line) and beg < col and line[beg] == " ":
                beg += 1
            lines[i] = line[beg:]

        # The resulting lines are Markdown format
        out.write("\n## Contents\n\n")
        out.write("\n".join(lines) + "\n")

    # Write section heading and download link
    out.write("\n## Metadata\n\n")
    name = entry.key + ".bib"
    down = '{download="' + name + '"}'
    out.write(f"[:material-download: Download .bib file]({name}){down}\n\n")

    # Write field-value pairs in table format
    out.write("Field | Value\n------|------\n")
    for fkey, field in entry.fields_dict.items():
        if fkey in ["abstract", "contents"]:
            continue
        out.write(f"{fkey} | ")
        if fkey != "url":
            out.write(f"{field.value}\n")
        else:
            # Abbreviate the URL to allow text wrapping
            url = field.value
            abbr = abbreviate(url)
            out.write(f"[{abbr}]({url})\n")


def write_page(entry, out):
    """Generate a standalone page for the entry (publication)."""

    # Create a reference format string
    author, year, title, source = get_fields(entry)
    ref = f"{author}. ({year}). {title}."
    if source:
        if entry.entry_type.startswith("in"):
            ref += f" In *{source}*."
        else:
            ref += f" *{source}*."

    # Generate the top section of the page
    # out.write("---\nhide:\n  - toc\n---\n\n")
    out.write(WARN + "\n\n")
    out.write(f"# {title}\n\n")
    out.write(f"**Reference:** {ref}\n\n")
    out.write('<div class="grid" markdown="1">\n\n')
    out.write(f"**Entry Key:** `#!tex \\cite{{{entry.key}}}`\n\n")
    out.write(f"**Entry Type:** `@{entry.entry_type}`\n\n")
    out.write("</div>\n")

    # Generate the entry section of the page
    write_entry(entry, out)


def sort_key(item):
    """Sort bullet lists on index pages."""
    if item[0].startswith("a"):
        # Activities index: sort by scr_uri
        return item[0]
    else:
        # Research index: sort by (year desc, title)
        fields = item[1].fields_dict
        year = int(fields["year"].value)
        title = fields["title"].value
        return (-year, title)


def write_index(name, entries_dict, out):
    """Generate an index page for the given entities (ACTS or PUBS)."""
    out.write(WARN + "\n")
    prev_dir = None
    items = sorted(entries_dict.items(), key=sort_key)
    for href, entry in items:
        # Remove top-level directory
        href = href[len(name)+1:]
        if href.endswith("bib"):
            href = href[:-3] + "md"

        # Subsection for each directory
        idx = href.find("/")
        curr_dir = href[:idx] if idx > -1 else None
        if curr_dir != prev_dir:
            out.write(f"\n## {curr_dir} ")
            out.write("{ data-search-exclude }\n\n")
            prev_dir = curr_dir

        # Bullet list item for each entry
        author, year, title, source = get_fields(entry)
        link = f"[**{title}**]({href})"
        out.write(f"* {link}<br>\n  ")
        out.write(f'<span class="smaller">{author} ({source} {year})</span>\n')


def on_files(files, config):
    """Called after the files collection is populated from the docs_dir."""
    removed_files = []
    virtual_files = []
    for file in files:
        uri = file.src_uri
        path = "docs/" + uri

        # If activity, find and parse the bibtex code block
        if uri.startswith("activities") and uri.endswith(".md"):
            with open(path) as f:
                content = f.read()
            pattern = r'```\s*bibtex\s*\n(.*?)\n```'
            match = re.search(pattern, content, re.DOTALL)
            if match:
                # Parse and save the entry
                code = match.group(1).strip()
                entry = parse_entry(code)
                ACTS[uri] = entry

                # Replace code block with markdown
                out = io.StringIO()
                write_entry(entry, out)
                content = content[:match.start()] + out.getvalue() + content[match.end():]
                removed_files.append(file)
                file = File.generated(config, uri, content=content)
                virtual_files.append(file)

                # Generate corresponding bib file
                file = File.generated(config, uri[:-2] + "bib", content=code)
                virtual_files.append(file)

                # Warn if more than one code block
                rest = content[match.end():]
                match = re.search(pattern, rest, re.DOTALL)
                if match:
                    LOG.warning("More than one bibtex entry found in " + uri)

        # If publication, parse bib file and generate md file
        if uri.startswith("research") and uri.endswith(".bib"):
            # Parse and save the entry
            entry = parse_entry(path)
            PUBS[uri] = entry

            # Replace code block with markdown
            out = io.StringIO()
            write_page(entry, out)
            content = out.getvalue()
            file = File.generated(config, uri[:-3] + "md", content=content)
            virtual_files.append(file)

            # Warn if cite key does not match
            if not uri[:-4].endswith(entry.key):
                LOG.warning(f"Cite key {entry.key} does not match filename " + uri)

    # Replace modified activity files, add generated publication files
    for file in removed_files:
        files.remove(file)
    for file in virtual_files:
        files.append(file)


def on_page_markdown(markdown, page, config, files):
    """Called after the page's markdown is loaded from the source file."""

    # Activities index
    if page.url == "activities/":
        out = io.StringIO()
        write_index("activities", ACTS, out)
        return markdown + out.getvalue()

    # Publications index
    if page.url == "research/":
        out = io.StringIO()
        write_index("research", PUBS, out)
        return markdown + out.getvalue()
