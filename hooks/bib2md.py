"""Parse all BibTeX entries and generate the corresponding Markdown content.

The `on_files` hook parses all activities and research files, populates the
global `ACTS` and `PUBS` variables, and adds new files to the build output:

  - For each activity page, a `.bib` file is generated (see `write_entry`).
  - For each research page, a `.md` file is generated (see `write_page`).

The `on_page_markdown` hook generates a table of contents at the bottom of
`activities/index.md` and `research/index.md` (see `write_index`).
"""

import io
import logging
import re

import bibtexparser
from bibtexparser.model import Entry
from jinja2 import Environment, FileSystemLoader
from mkdocs.structure.files import File

ENV = Environment(loader=FileSystemLoader("templates"))
LOG = logging.getLogger("mkdocs")

# Warning at the top of each generated Markdown file
WARN = "<!-- DO NOT EDIT THIS FILE (automatically generated by bib2md.py) -->"

# All activities and publications (map src_uri to bibtex Entry)
ACTS: list[tuple[str, Entry]] = []
PUBS: list[tuple[str, Entry]] = []


def parse_entry(code_or_path):
    """Parse the given code block or bib file and return the entry."""

    # Is the string a code block or file path?
    if code_or_path.startswith("@"):
        library = bibtexparser.parse_string(code_or_path)
    else:
        library = bibtexparser.parse_file(code_or_path)

    # Abort if the BiBTeX format is incorrect
    n = len(library.failed_blocks)
    if n > 0:
        LOG.warning(f"{n} blocks failed to parse")
    n = len(library.entries)
    if n != 1:
        LOG.warning(f"{n} entries found (not 1)")

    # Replace LaTeX escape sequences for Markdown
    entry = library.entries[0]
    for field in entry.fields:
        field.value = field.value.replace("\\&", "&")
    return entry


def reformat_authors(author_string):
    """Convert author string to "First Last" format, separated by commas."""
    authors = author_string.split(" and ")
    reformatted = []
    for author in authors:
        if "," in author:
            last, first = [part.strip() for part in author.split(",", 1)]
            reformatted.append(f"{first} {last}")
        else:
            # Already in "First Last" format
            reformatted.append(author.strip())
    return ", ".join(reformatted)


def abbreviate(url):
    """Shorten the URL for better text wrapping."""
    pos = url.index("/", 8)
    return url[:pos+1] + "..."


def get_fields(entry):
    """Extract fields used in references and summary tables."""

    # entry.fields is list[Field]; convert to dict[str, str]
    fields = {field.key: field.value for field in entry.fields}

    # standardize the author format
    fields["author"] = reformat_authors(fields["author"])

    # Get the source in order of priority
    for fkey in ["booktitle", "journal", "publisher", "howpublished"]:
        if fkey in fields:
            fields["source"] = fields[fkey]
            break

    # Default to short url if not found
    if "source" not in fields:
        url = fields["url"]
        abbr = abbreviate(url)
        fields["source"] = f"[{abbr}]({url})"

    return fields


def write_entry(entry, out):
    """Output the entry (activity or publication) in Markdown format."""

    # Write the "Abstract" section if present
    field = entry.fields_dict.get("abstract")
    if field:
        out.write("\n## Abstract\n\n")
        out.write(field.value + "\n")

    # Write the "Contents" section if present
    field = entry.fields_dict.get("contents")
    if field:

        # Get the index after the left brace
        pattern = r"^\s*contents\s*=\s*{"
        match = re.search(pattern, entry.raw, re.MULTILINE)
        assert match is not None
        col = len(match.group())

        # Remove leading whitespace from each line
        lines = field.value.splitlines()
        for i in range(1, len(lines)):
            line = lines[i]
            beg = 0
            while beg < len(line) and beg < col and line[beg] == " ":
                beg += 1
            lines[i] = line[beg:]

        # The resulting lines are Markdown format
        out.write("\n## Contents\n\n")
        out.write("\n".join(lines) + "\n")

    # Write section heading and download link
    out.write("\n## Metadata\n\n")
    name = entry.key + ".bib"
    down = '{download="' + name + '"}'
    out.write(f"[:material-download: Download .bib file]({name}){down}\n\n")

    # Write field-value pairs in table format
    out.write("Field | Value\n------|------\n")
    for fkey, field in entry.fields_dict.items():
        if fkey in ["abstract", "contents"]:
            continue
        out.write(f"{fkey} | ")
        if fkey != "url":
            out.write(f"{field.value}\n")
        else:
            # Abbreviate the URL to allow text wrapping
            url = field.value
            abbr = abbreviate(url)
            out.write(f"[{abbr}]({url})\n")


def write_page(entry, out):
    """Generate a standalone page for the entry (publication)."""

    # Get the tags based on entry metadata
    tags = []
    for keyword in ["SIGCSE", "ITiCSE", "ASEE", "PLoP", "Inroads"]:
        if keyword in entry.raw:
            tags.append(keyword)
    if not tags:
        tags.append(entry.entry_type)

    # Generate the top section of the page
    out.write("---\ntags:\n  - ")
    out.write("\n  - ".join(tags))
    out.write("\n---\n\n")
    out.write(WARN + "\n\n")

    # Render the research page template
    template = ENV.get_template("research.md")
    rendered = template.render(**get_fields(entry))
    out.write(rendered)

    # Generate the entry section of the page
    write_entry(entry, out)


def sort_key(item):
    """Sort bullet lists on index pages."""
    if item[0].startswith("a"):
        # Activities index: sort by scr_uri
        return item[0]
    else:
        # Research index: sort by (year desc, title)
        fields = item[1].fields_dict
        year = int(fields["year"].value)
        title = fields["title"].value
        return (-year, title)


def write_index(name, items, out):
    """Generate an index page for the given items (ACTS or PUBS)."""
    out.write(WARN + "\n")
    prev_dir = None
    template = ENV.get_template("listitem.md")
    for href, entry in items:

        # Remove top-level directory
        href = href[len(name)+1:]
        if href.endswith("bib"):
            href = href[:-3] + "md"

        # Subsection for each directory
        idx = href.find("/")
        curr_dir = href[:idx] if idx > -1 else None
        if curr_dir != prev_dir:
            out.write(f"\n## {curr_dir} ")
            out.write("{ data-search-exclude }\n\n")
            prev_dir = curr_dir

        # Bullet list item for each entry
        rendered = template.render(href=href, **get_fields(entry))
        out.write(rendered)


def on_files(files, config):
    """Called after the files collection is populated from the docs_dir."""
    ACTS.clear()
    PUBS.clear()
    removed_files = []
    virtual_files = []
    for file in files:
        uri = file.src_uri
        path = "docs/" + uri

        # If activity, find and parse the bibtex code block
        if uri.startswith("activities") and uri.endswith(".md"):
            with open(path) as f:
                content = f.read()
            pattern = r"```\s*bibtex\s*\n(.*?)\n```"
            match = re.search(pattern, content, re.DOTALL)
            if match:
                # Parse and save the entry
                code = match.group(1).strip()
                entry = parse_entry(code)
                ACTS.append((uri, entry))

                # Replace code block with markdown
                out = io.StringIO()
                write_entry(entry, out)
                content = content[:match.start()] + out.getvalue() + content[match.end():]
                removed_files.append(file)
                file = File.generated(config, uri, content=content)
                virtual_files.append(file)

                # Generate corresponding bib file
                file = File.generated(config, uri[:-2] + "bib", content=code)
                virtual_files.append(file)

                # Warn if more than one code block
                rest = content[match.end():]
                match = re.search(pattern, rest, re.DOTALL)
                if match:
                    LOG.warning("More than one bibtex entry found in " + uri)

        # If publication, parse bib file and generate md file
        if uri.startswith("research") and uri.endswith(".bib"):
            # Parse and save the entry
            entry = parse_entry(path)
            PUBS.append((uri, entry))

            # Replace code block with markdown
            out = io.StringIO()
            write_page(entry, out)
            content = out.getvalue()
            file = File.generated(config, uri[:-3] + "md", content=content)
            virtual_files.append(file)

            # Warn if cite key does not match
            if not uri[:-4].endswith(entry.key):
                LOG.warning(f"Cite key {entry.key} does not match filename " + uri)

    # Sort global collections before generating index and people pages
    ACTS.sort(key=sort_key)
    PUBS.sort(key=sort_key)

    # Replace modified activity files, add generated publication files
    for file in removed_files:
        files.remove(file)
    for file in virtual_files:
        files.append(file)


def on_page_markdown(markdown, page, config, files):
    """Called after the page's markdown is loaded from the source file."""

    # Activities index
    if page.url == "activities/":
        out = io.StringIO()
        write_index("activities", ACTS, out)
        return markdown + out.getvalue()

    # Publications index
    if page.url == "research/":
        out = io.StringIO()
        write_index("research", PUBS, out)
        return markdown + out.getvalue()
